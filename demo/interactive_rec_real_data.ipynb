{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a41a83e-a373-4669-a008-bc60bf50f741",
   "metadata": {},
   "source": [
    "# Experimental data reconstruction (user data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be405de-6c02-42be-becd-b67698cf073c",
   "metadata": {},
   "source": [
    "## **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68d2c34-55e4-4bbf-8ff2-ea71f2c17c63",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-29T04:51:15.816121Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4,5,6,7\"         # set your preferred cuda visible device\n",
    "os.chdir('..')\n",
    "from parameters import *\n",
    "from PtyINR.train import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d940fa7-080f-4a02-9d40-d09ab9f967f9",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "You may also change hyperparameters from parameters.py\n",
    "\n",
    "Notice that though sometimes the loss seem to be converged without changing, it is in fact not. It is always good to run a few hundred steps more to reach better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1114421a-98e7-4709-8fe0-cb966b1b181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[\"tag\"]=\"experimental_data\"  # final output file name\n",
    "parameters[\"total_steps\"]= 300         # total training steps\n",
    "parameters[\"probe_known\"]= False        # probe is provided or not\n",
    "parameters[\"diffraction_scale\"]=400        # the diffraction patterns will be divided by this value to ensure the loss is not too large for optimization as LR is usually below 1\n",
    "parameters[\"batches\"]=1300                # batch size for each loss backward\n",
    "parameters[\"LR\"]=6e-5                      # for object amplitude  \n",
    "parameters[\"LR2\"]=6e-5                     # for object phase \n",
    "parameters[\"LR3\"]=5e-5                     # for probe amplitude\n",
    "parameters[\"LR4\"]=5e-5                     # for probe phase\n",
    "parameters[\"regularized_loss_weight\"]=1e-2\n",
    "parameters[\"regularized_steps\"]=50\n",
    "parameters[\"show_every\" ]=10\n",
    "parameters[\"first_omega\" ]=30                 # adjust it higher to get better details, please see paper for more details on this parameter\n",
    "parameters[\"loss\"]=\"SmoothL1\"\n",
    "parameters[\"beta_for_smoothl1\"]=1e-5\n",
    "parameters[\"model_type\" ]=\"siren\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f219541-66b0-4690-bafe-986c2b031680",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters[\"show_every\"]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c26361-c338-454d-9f10-2c21b818b84a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stocastic gradient descent(SGD)!\n",
      "\n",
      "Please use tensor board to see the intermediate images.\n",
      "The tensor board files are stored in the folder:  result/tb\n",
      "The images of latest reconstructions can be found at :  result/ \n",
      "\n",
      "[GPU 3] diffraction patterns shape (40401, 220, 220)\n",
      "[GPU 2] diffraction patterns shape (40401, 220, 220)\n",
      "[GPU 0] diffraction patterns shape (40401, 220, 220)\n",
      "[DDP] Requested global batch=1300 -> per-rank batch=325 (effective global=1300)\n",
      "[GPU 1] diffraction patterns shape (40401, 220, 220)\n",
      "using SmoothL1 loss for training!\n",
      "[GPU 0] Step 0, global accumulated loss: 80.663251\n",
      "[GPU 0] Step 10, global accumulated loss: 33.904085\n",
      "[GPU 0] Step 20, global accumulated loss: 33.010641\n",
      "[GPU 0] Step 30, global accumulated loss: 32.061158\n",
      "[GPU 0] Step 40, global accumulated loss: 31.768030\n",
      "[GPU 0] Step 50, global accumulated loss: 31.427146\n",
      "[GPU 0] Step 60, global accumulated loss: 31.337189\n",
      "[GPU 0] Step 70, global accumulated loss: 38.041908\n",
      "[GPU 0] Step 80, global accumulated loss: 31.175491\n",
      "[GPU 0] Step 90, global accumulated loss: 31.149882\n",
      "[GPU 0] Step 100, global accumulated loss: 31.092484\n",
      "[GPU 0] Step 110, global accumulated loss: 31.029270\n",
      "[GPU 0] Step 120, global accumulated loss: 31.057859\n",
      "[GPU 0] Step 130, global accumulated loss: 30.915395\n",
      "[GPU 0] Step 140, global accumulated loss: 30.868535\n",
      "[GPU 0] Step 150, global accumulated loss: 30.766969\n",
      "[GPU 0] Step 160, global accumulated loss: 30.682204\n",
      "[GPU 0] Step 170, global accumulated loss: 30.577104\n",
      "[GPU 0] Step 180, global accumulated loss: 30.480057\n",
      "[GPU 0] Step 190, global accumulated loss: 30.318263\n",
      "[GPU 0] Step 200, global accumulated loss: 30.194552\n",
      "[GPU 0] Step 210, global accumulated loss: 30.063390\n",
      "[GPU 0] Step 220, global accumulated loss: 33.189607\n",
      "[GPU 0] Step 230, global accumulated loss: 31.314863\n",
      "[GPU 0] Step 240, global accumulated loss: 30.897322\n",
      "[GPU 0] Step 250, global accumulated loss: 30.731634\n",
      "[GPU 0] Step 260, global accumulated loss: 30.540422\n",
      "[GPU 0] Step 270, global accumulated loss: 30.453858\n",
      "[GPU 0] Step 280, global accumulated loss: 30.347906\n",
      "[GPU 0] Step 290, global accumulated loss: 30.368482\n",
      "\n",
      " Training completed in 1858.50 seconds (30.97 minutes).\n"
     ]
    }
   ],
   "source": [
    "train_model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b8f6e-cfd8-4e48-88e0-0602d04d75b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
